{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melbow2424/Data-602-Assignment-7/blob/main/07_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd2QZetSDszc"
      },
      "source": [
        "# **Assignment 7**\n",
        "\n",
        "# **Weeks 8 & 9 - Pandas**\n",
        "* In this homework assignment, you will explore and analyze a public dataset of your choosing. Since this assignment is “open-ended” in nature, you are free to expand upon the requirements below. However, you must meet the minimum requirments as indicated in each section. \n",
        "\n",
        "* You must use Pandas as the **primary tool** to process your data.\n",
        "\n",
        "* The preferred method for this analysis is in a .ipynb file. Feel free to use whichever platform of your choosing.  \n",
        " * https://www.youtube.com/watch?v=inN8seMm7UI (Getting started with Colab).\n",
        "\n",
        "* Your data should need some \"work\", or be considered \"dirty\".  You must show your skills in data cleaning/wrangling.\n",
        "\n",
        "### **Some data examples:**\n",
        "•\thttps://www.data.gov/\n",
        "\n",
        "•\thttps://opendata.cityofnewyork.us/\n",
        "\n",
        "•\thttps://datasetsearch.research.google.com/\n",
        "\n",
        "•\thttps://archive.ics.uci.edu/ml/index.php\n",
        "\n",
        "### **Resources:**\n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html \n",
        "\n",
        "•\thttps://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html\n",
        "\n",
        "\n",
        "### **Headings or comments**\n",
        "**You are required to make use of comments, or headings for each section.  You must explain what your code is doing, and the results of running your code.**  Act as if you were giving this assignment to your manager - you must include clear and descriptive information for each section.\n",
        "\n",
        "### **You may work as a group or indivdually on this assignment.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW3w6p8rqgxu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this section, please describe the dataset you are using.  Include a link to the source of this data.  You should also provide some explanation on why you choose this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PnfMOFzOXz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bp8cdDxDs2t"
      },
      "source": [
        "______________\n",
        "# Data Exploration\n",
        "Import your dataset into your .ipynb, create dataframes, and explore your data.  \n",
        "\n",
        "Include: \n",
        "\n",
        "* Summary statistics means, medians, quartiles, \n",
        "* Missing value information\n",
        "* Any other relevant information about the dataset.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJmbafkEhhq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0WTKtqozNn1"
      },
      "source": [
        "#read from csv: Play Store Apps Web scraped data of 10k Play Store apps (https://www.kaggle.com/datasets/whenamancodes/play-store-apps?select=googleplaystore.csv)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/melbow2424/Data-602-Assignment-7/main/googleplaystore.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using head function to make sure csv data frame was created\n",
        "df.head()"
      ],
      "metadata": {
        "id": "II9s7CrF9a1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics means, medians, quartiles for all the columns. \n",
        "df.describe(include='all') "
      ],
      "metadata": {
        "id": "U8irYUti90eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the NaN values in all the columns. Overview of missing value information\n",
        "display(df.isnull().sum())"
      ],
      "metadata": {
        "id": "f7UStEAQD4MS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCSLIafaEGVK"
      },
      "source": [
        "# Data Wrangling\n",
        "Create a subset of your original data and perform the following.  \n",
        "\n",
        "1. Modify multiple column names.\n",
        "\n",
        "2. Look at the structure of your data – are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed.\n",
        "\n",
        "3. Fix missing and invalid values in data.\n",
        "\n",
        "4. Create new columns based on existing columns or calculations.\n",
        "\n",
        "5. Drop column(s) from your dataset.\n",
        "\n",
        "6. Drop a row(s) from your dataset.\n",
        "\n",
        "7. Sort your data based on multiple variables. \n",
        "\n",
        "8. Filter your data based on some condition. \n",
        "\n",
        "9. Convert all the string values to upper or lower cases in one column.\n",
        "\n",
        "10. Check whether numeric values are present in a given column of your dataframe.\n",
        "\n",
        "11. Group your dataset by one column, and get the mean, min, and max values by group. \n",
        "  * Groupby()\n",
        "  * agg() or .apply()\n",
        "\n",
        "12. Group your dataset by two columns and then sort the aggregated results within the groups. \n",
        "\n",
        "**You are free (and should) to add on to these questions.  Please clearly indicate in your assignment your answers to these questions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR-6Fso5SWuU"
      },
      "source": [
        "# Modify multiple column names. df.reman rename specific columns in a pandas DataFrame\n",
        "df.rename(columns = {'App':'Application_Name', \n",
        "                     'Size' : 'Size (M)',\n",
        "                     'Content Rating':'Content_Rating', \n",
        "                     'Android Ver':'Android_Version',\n",
        "                     'Current Ver':'Current_Version'}, inplace = True)\n",
        "\n",
        "list(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the structure of your data to see if variables improperly coded\n",
        "print(\"Data Types of The Columns in Data Frame\")\n",
        "display(df.dtypes)"
      ],
      "metadata": {
        "id": "SshtuQj9XR5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Trying to convert a string data type to an integer values, I find a row of information that was missing its Category info and thus all its scrapped into was shifted to the left. \n",
        "It is displayed below and the Error is a follows: \n",
        "ValueError: Unable to parse string \"3.0M\" at position 10472\n",
        "\"\"\"\n",
        "\n",
        "print(\"Value of row at position 10472\")\n",
        "display(df.iloc[10472])"
      ],
      "metadata": {
        "id": "AhAJUGvtSpdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Because of this, I will be dropping a row from the dataset here: \n",
        "#Drop a row(s) from your dataset.\n",
        "\n",
        "df1 = df.drop(index=[10472])\n",
        "display(df1.iloc[10472])"
      ],
      "metadata": {
        "id": "5kfzVelDUk0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# On review of the data type Reviews and Installs should be either integer values. These will need to be corrected. \n",
        "# Convert to correct data type structure\n",
        "\n",
        "# Reviews \n",
        "# Convert string to an integer for column Reviews\n",
        "df1['Reviews'] = df1['Reviews'].astype(int)\n",
        "\n",
        "display(df1.dtypes)\n"
      ],
      "metadata": {
        "id": "nATPKSaNXD9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix invalid values in data.\n",
        "# Installs  \n",
        "# Installs had a string value of + and ,. They need to dropped before the Installs data type can be changed \n",
        "\n",
        "#df2 = df1['Installs'].str.extract('(\\d+)', expand=False) \n",
        "\n",
        "#Dropping M from Size\n",
        "df1['Installs'] = df1['Installs'].str.replace('+','')\n",
        "df1['Installs'] = df1['Installs'].str.replace(',','')\n",
        "#Displaying it to show it was dropped. \n",
        "df1.head()"
      ],
      "metadata": {
        "id": "WDDhcFJMfsNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs\n",
        "# Convert string to an integer for column Installs\n",
        "df1['Installs'] = df1['Installs'].astype(int)\n",
        "\n",
        "display(df1.dtypes)"
      ],
      "metadata": {
        "id": "g3hMSAlxgNqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new columns based on existing columns or calculations.\n",
        "\n",
        "#Wanted to see which apps had more than 100,000 downloads, thus a column named Over 100000 was created. \n",
        "#If there are over 100,000 downloads for an app, a yes is placed in the column else a no is placed in the column. \n",
        "df1['Over 100000'] = np.where(df1['Installs']>= 100000, 'yes', 'no')\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "LH-xYjo6kc6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop column(s) from your dataset.\n",
        "df1.drop('Android_Version', axis=1, inplace=True)\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "XIhv-Axw5hqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort your data based on multiple variables.\n",
        "# Sorting by Category value in ascending order then Content_Rating in descending order\n",
        "df1.sort_values(by = ['Category', 'Content_Rating'], ascending = [True, False])\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "z2JN6sEu342i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter your data based on some condition.\n",
        "# Filtered data set based on Rating column being greater than 3.5 \n",
        "df1[df1['Rating'] > 3.5] "
      ],
      "metadata": {
        "id": "TWa4KX9PEQkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all the string values to upper or lower cases in one column.\n",
        "df1.Content_Rating.str.upper()"
      ],
      "metadata": {
        "id": "NXDDMISsDEq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether numeric values are present in a given column of your dataframe.\n",
        "df1['Size (M)'].str.isnumeric()"
      ],
      "metadata": {
        "id": "D4kdo8B4GPnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group your dataset by one column, and get the mean, min, and max values by group.\n",
        "# Mean, min, and max values of Installs grouped by app Category \n",
        "df1.groupby('Category').agg({'Installs': ['mean', 'min', 'max']})"
      ],
      "metadata": {
        "id": "xi6Cm0ZFI0MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group your dataset by two columns and then sort the aggregated results within the groups.\n",
        "# Grouped by Category and Installed then aggregated the results by the mean. \n",
        "# Interestingly got the same mean vales as if I group by the Category then aggregated over the Installs. \n",
        "df1.groupby('Category')['Installs'].mean() "
      ],
      "metadata": {
        "id": "8nBhlXxsKUBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions  \n",
        "\n",
        "After exploring your dataset, provide a short summary of what you noticed from this dataset.  What would you explore further with more time?\n",
        "\n",
        "\n",
        "\n",
        "Pandas is a powerful package that can manipulate data frames in multiple ways. It can be used to filter information, change variables inside of a column, summaries, and it can even add columns based on existing. From the data set used, I noticed there was a lot of tiding need in the data before manipulation. Especially when most numeric values were interpreted as strings and therefore needed corrections. If I had more time, I would work on making the Size column into a float variable and not a string variable. Below you can even see the code I started to work on to do just that, but it got complex. As you can see in the data set the Size columns had an M next to its variables. I though I could just drop that value, but I then ran into other issues. There were also variables with k next to its variables as well as column which said, “Varies with device”. Too correct everything, I know I would need to change the columns that said “Varies with device” into NaN values and figure out a way to take the M and k values and multiply them by a million and a thousand respectfully (or something like that). \n"
      ],
      "metadata": {
        "id": "tujjevRpXEen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Size \n",
        "# Size had a string value M before its numbers. That needs to dropped before the Size data type can be changed \n",
        "\n",
        "#df2 = df1['Installs'].str.extract('(\\d+)', expand=False) \n",
        "\n",
        "#Dropping M from Size\n",
        "#df1['Size (M)'] = df1['Size (M)'].str.replace('M','')\n",
        "#Displaying it to show it was dropped. \n",
        "#df1.head()\n",
        "\n",
        "#df1['Size (M)'] = df1['Size (M)'].replace('Varies with device', np.NaN, regex=True)\n",
        "#df1.head()\n",
        "\n",
        "#df1['Size (M)'] = df1['Size (M)'].str.replace('201k', '0.201')\n",
        "#df1['Size (M)'] = df1['Size (M)'].str.replace('23k', '0.023')\n",
        "#df1.head()\n",
        "\n",
        "# Convert string to an float for column Size\n",
        "#df1['Size (M)'] = df1['Size (M)'].astype(float)\n",
        "\n",
        "#display(df1.dtypes)"
      ],
      "metadata": {
        "id": "iGfYPceauNDz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}